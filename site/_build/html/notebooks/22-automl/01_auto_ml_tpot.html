

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Introduction: Automated Machine Learning &#8212; MGMT 4100/6560 Introduction to Machine Learning Applications @Rensselaer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">MGMT 4100/6560 Introduction to Machine Learning Applications @Rensselaer</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome to Introduction to Machine Learning Applications
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  OVERVIEW
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/schedule.html">
   Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/preparation.html">
   Before Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/in_class.html">
   In Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/assignments.html">
   Assignments
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  SESSIONS
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session1.html">
   1. Course Overview &amp; Introduction to the Data Science Lifecycle (08/31)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session2.html">
   2. Python Basics (09/03)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session3.html">
   3. Python Basics  (First in Person Class, Tuesday follow Monday Schedule) (09/08)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session4.html">
   4. Python conditionals, loops, functions, aggregating.  (09/10)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  NOTEBOOKS
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/01-python-overview.html">
   1. Overview of Python Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/02-datastructures.html">
   2. Introduction Datastructures (Varibles, Lists, Dictionaries, and Sets)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/03-numpy.html">
   3. Overview of Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/04-pandas.html">
   4. Large sections of this were adopted from Analyzing structured data with Pandas by Steve Phelps.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/04-pandas.html#introduction-to-pandas">
   5. Introduction to Pandas
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/22-automl/01_auto_ml_tpot.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/rpi-techfundamentals/introml_website_fall_2020"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/rpi-techfundamentals/introml_website_fall_2020/issues/new?title=Issue%20on%20page%20%2Fnotebooks/22-automl/01_auto_ml_tpot.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/rpi-techfundamentals/introml_website_fall_2020/blob/master/site/notebooks/22-automl/01_auto_ml_tpot.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            
        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <center>[![AnalyticsDojo](https://raw.githubusercontent.com/rpi-techfundamentals/fall2018-materials/master/fig/final-logo.png)](http://rpi.analyticsdojo.com)
<h1>Ludwig</h1></center>
<center><h3><a href = 'http://rpi.analyticsdojo.com'>AutoML with TPOT</a></h3></center><p>Adopted from: https://towardsdatascience.com/automated-machine-learning-on-the-cloud-in-python-47cf568859f</p>
<div class="section" id="introduction-automated-machine-learning">
<h1>Introduction: Automated Machine Learning<a class="headerlink" href="#introduction-automated-machine-learning" title="Permalink to this headline">¶</a></h1>
<p>In this notebook, we will see how to use <a class="reference external" href="https://epistasislab.github.io/tpot/api/">TPOT</a>, a Python library developed for automatic machine learning feature preprocessing, model selection, and hyperparameter tuning. Using <a class="reference external" href="http://geneticprogramming.com/tutorial/">genetic programming</a>, TPOT tries to find the best machine learning pipeline for a dataset by evaluating thousands of possibilites.</p>
<p>The machine learning pipeline in this context consists of:</p>
<ol class="simple">
<li><p>Feature Preprocessing</p></li>
</ol>
<ul class="simple">
<li><p>Imputing missing values and scaling values</p></li>
<li><p>Constructing new features such as polynomial transformations</p></li>
</ul>
<ol class="simple">
<li><p>Feature selection</p></li>
</ol>
<ul class="simple">
<li><p>Dimensionality reduction, for example using PCA and other techniques</p></li>
</ul>
<ol class="simple">
<li><p>Model Selection</p></li>
</ol>
<ul class="simple">
<li><p>Evaluting a number of machine learning models</p></li>
</ul>
<ol class="simple">
<li><p>Hyperparameter tuning</p></li>
</ol>
<ul class="simple">
<li><p>Finding the optimal settings of the model for the particular problem</p></li>
</ul>
<p>TPOT is one of a class of methods known as <a class="reference external" href="https://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html">auto-ml (short for automated machine learning)</a> which aim to simplify the work of the data scientist by automatically finding the optimal (or near-optimal) feature preprocessing steps and model for the problem. Machine learning is  typically a very time-consuming and knowledge-intensive part of a data science problem. Auto-ml is not designed to replace the data scientist, but rather free her to work on more important aspects of the complete problem, such as acquiring data and interpreting the model results. In effect, TPOT, and auto-ml in general, will in effect be a “data science assistant” that will be another tool among many used by data scientists. Machine learning is only one part of the data science process, and it still takes a human to weave the different aspects of a problem together into a complete working product.</p>
<p>Other entries in the field of auto - ml include:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://automl.github.io/auto-sklearn/stable/">Auto-sklearn</a></p></li>
<li><p><a class="reference external" href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html">H20</a></p></li>
<li><p><a class="reference external" href="https://cloud.google.com/automl/">Google Cloud AutoML</a></p></li>
</ul>
<p>With that background, let’s see how automated machine learning, the future of data science, works!</p>
<p>First, because we are working in Google Colab, we need to make sure to install <code class="docutils literal notranslate"><span class="pre">TPOT</span></code>. We can do that using a system command (which in Jupyter is proceeded by <code class="docutils literal notranslate"><span class="pre">!</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># Install tpot on the server
!pip install tpot
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting tpot
[?25l  Downloading https://files.pythonhosted.org/packages/36/6f/9a400b0a7d32d13b1b9a565de481d10163c8b39d1bdf63ae0219922a24fb/TPOT-0.10.0-py3-none-any.whl (73kB)
[K    100% |████████████████████████████████| 81kB 5.1MB/s 
[?25hCollecting stopit&gt;=1.1.1 (from tpot)
  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz
Collecting update-checker&gt;=0.16 (from tpot)
  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl
Requirement already satisfied: pandas&gt;=0.20.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.23.4)
Requirement already satisfied: scikit-learn&gt;=0.18.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.20.3)
Requirement already satisfied: tqdm&gt;=4.26.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.28.1)
Requirement already satisfied: scipy&gt;=0.19.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.2.1)
Collecting deap&gt;=1.0 (from tpot)
[?25l  Downloading https://files.pythonhosted.org/packages/af/29/e7f2ecbe02997b16a768baed076f5fc4781d7057cd5d9adf7c94027845ba/deap-1.2.2.tar.gz (936kB)
[K    100% |████████████████████████████████| 942kB 18.9MB/s 
[?25hRequirement already satisfied: numpy&gt;=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.16.2)
Requirement already satisfied: requests&gt;=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker&gt;=0.16-&gt;tpot) (2.18.4)
Requirement already satisfied: pytz&gt;=2011k in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.20.2-&gt;tpot) (2018.9)
Requirement already satisfied: python-dateutil&gt;=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.20.2-&gt;tpot) (2.5.3)
Requirement already satisfied: urllib3&lt;1.23,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.3.0-&gt;update-checker&gt;=0.16-&gt;tpot) (1.22)
Requirement already satisfied: idna&lt;2.7,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.3.0-&gt;update-checker&gt;=0.16-&gt;tpot) (2.6)
Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.3.0-&gt;update-checker&gt;=0.16-&gt;tpot) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.3.0-&gt;update-checker&gt;=0.16-&gt;tpot) (2019.3.9)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil&gt;=2.5.0-&gt;pandas&gt;=0.20.2-&gt;tpot) (1.11.0)
Building wheels for collected packages: stopit, deap
  Building wheel for stopit (setup.py) ... [?25ldone
[?25h  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7
  Building wheel for deap (setup.py) ... [?25ldone
[?25h  Stored in directory: /root/.cache/pip/wheels/22/ea/bf/dc7c8a2262025a0ab5da9ef02282c198be88902791ca0c6658
Successfully built stopit deap
Installing collected packages: stopit, update-checker, deap, tpot
Successfully installed deap-1.2.2 stopit-1.1.2 tpot-0.10.0 update-checker-0.16
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># pandas and numpy for data manipulation</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Import the tpot regressor</span>
<span class="kn">from</span> <span class="nn">tpot</span> <span class="kn">import</span> <span class="n">TPOTRegressor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-1-aa36b760643a&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># Import the tpot regressor</span>
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">tpot</span> <span class="kn">import</span> <span class="n">TPOTRegressor</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;tpot&#39;

<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NOTE</span>: If your import is failing due to a missing package, you can
<span class="n">manually</span> <span class="n">install</span> <span class="n">dependencies</span> <span class="n">using</span> <span class="n">either</span> <span class="o">!</span>pip or !apt.

<span class="n">To</span> <span class="n">view</span> <span class="n">examples</span> <span class="n">of</span> <span class="n">installing</span> <span class="n">some</span> <span class="n">common</span> <span class="n">dependencies</span><span class="p">,</span> <span class="n">click</span> <span class="n">the</span>
<span class="s2">&quot;Open Examples&quot;</span> <span class="n">button</span> <span class="n">below</span><span class="o">.</span>
<span class="gt">---------------------------------------------------------------------------</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="problem-description">
<h1>Problem Description<a class="headerlink" href="#problem-description" title="Permalink to this headline">¶</a></h1>
<p>The task is a supervised regression problem: given <a class="reference external" href="http://www.nyc.gov/html/gbee/html/plan/ll84_scores.shtml">New York City energy data</a>, we want to build a model that can predict the Energy Star Score of a building. In a series of articles (<a class="reference external" href="https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420">part one</a>, <a class="reference external" href="https://towardsdatascience.com/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2">part two</a>, <a class="reference external" href="https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-three-388834e8804b">part three</a>, <a class="reference external" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough">code on GitHub</a>), we built a complete machine learning solution for this problem. Using manual feature engineering, dimensionality reduction, model selection, and hyperparameter tuning, we were able to build a model that achieved a mean absolute error of 9.06 points (on a scale of 1-100) on the test set.</p>
<div class="section" id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<p>The features contain a number of continuous numeric variables (such as energy use and area of the building) as well as two one-hot encoded categorical variables (borough and building type). There are a total of 82 features.</p>
<p>All of the missing values have been encoded as <code class="docutils literal notranslate"><span class="pre">np.nan</span></code>, and TPOT will automatically perform missing value imputation. It also automatically scales the variables so we do not have to worry about normalizing the range of each feature. TPOT does both feature engineering and feature selection, so we will not transform any of the variables or remove extraneous features we think may be extraneous.</p>
<p>We will read into the data from GitHub and take a brief look.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read in features from GitHub</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project-walkthrough/master/data/X_train.csv&#39;</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project-walkthrough/master/data/X_test.csv&#39;</span><span class="p">)</span>

<span class="c1"># Read in labels from GitHub</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project-walkthrough/master/data/Y_train.csv&#39;</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project-walkthrough/master/data/Y_test.csv&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training features shape: &#39;</span><span class="p">,</span> <span class="n">train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing features shape:  &#39;</span><span class="p">,</span> <span class="n">test_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Training features shape:  (6622, 82)
Testing features shape:   (2839, 82)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_features</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Order</th>
      <th>Property Id</th>
      <th>DOF Gross Floor Area</th>
      <th>Largest Property Use Type - Gross Floor Area (ft²)</th>
      <th>Year Built</th>
      <th>Number of Buildings - Self-reported</th>
      <th>Occupancy</th>
      <th>Site EUI (kBtu/ft²)</th>
      <th>Weather Normalized Site EUI (kBtu/ft²)</th>
      <th>Weather Normalized Site Electricity Intensity (kWh/ft²)</th>
      <th>...</th>
      <th>Largest Property Use Type_Restaurant</th>
      <th>Largest Property Use Type_Retail Store</th>
      <th>Largest Property Use Type_Self-Storage Facility</th>
      <th>Largest Property Use Type_Senior Care Community</th>
      <th>Largest Property Use Type_Social/Meeting Hall</th>
      <th>Largest Property Use Type_Strip Mall</th>
      <th>Largest Property Use Type_Supermarket/Grocery Store</th>
      <th>Largest Property Use Type_Urgent Care/Clinic/Other Outpatient</th>
      <th>Largest Property Use Type_Wholesale Club/Supercenter</th>
      <th>Largest Property Use Type_Worship Facility</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>13276</td>
      <td>5849784</td>
      <td>90300.0</td>
      <td>77300.0</td>
      <td>1950</td>
      <td>1</td>
      <td>100</td>
      <td>126.0</td>
      <td>136.8</td>
      <td>5.2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7377</td>
      <td>4398442</td>
      <td>52000.0</td>
      <td>52000.0</td>
      <td>1926</td>
      <td>1</td>
      <td>100</td>
      <td>95.4</td>
      <td>102.0</td>
      <td>4.7</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9479</td>
      <td>4665374</td>
      <td>104700.0</td>
      <td>105000.0</td>
      <td>1954</td>
      <td>1</td>
      <td>100</td>
      <td>40.4</td>
      <td>40.0</td>
      <td>3.8</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>14774</td>
      <td>3393340</td>
      <td>129333.0</td>
      <td>129333.0</td>
      <td>1992</td>
      <td>1</td>
      <td>100</td>
      <td>157.1</td>
      <td>163.1</td>
      <td>16.9</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3286</td>
      <td>2704325</td>
      <td>109896.0</td>
      <td>116041.0</td>
      <td>1927</td>
      <td>1</td>
      <td>100</td>
      <td>62.3</td>
      <td>68.2</td>
      <td>3.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 82 columns</p>
</div></div></div>
</div>
<p>In the code below, we convert to <code class="docutils literal notranslate"><span class="pre">numpy</span></code> arrays. This is not strictly necessary, but the labels should be converted to a one-dimensional vector (using <code class="docutils literal notranslate"><span class="pre">reshape</span></code> in the code below) or Scikit-Learn will show a warning message.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert to numpy arrays</span>
<span class="n">training_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_features</span><span class="p">)</span>
<span class="n">testing_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>

<span class="c1"># Sklearn wants the labels as one-dimensional vectors</span>
<span class="n">training_targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">testing_targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
</pre></div>
</div>
</div>
</div>
<p>After the minimal data preparation, we can create the TPOT optimizer. The syntax for <a class="reference external" href="https://epistasislab.github.io/tpot/using/#tpot-with-code">TPOT optimizers</a> is designed to be as close to that for Scikit-Learn models as possible.</p>
<p>The <a class="reference external" href="https://epistasislab.github.io/tpot/api/">default parameters for TPOT optimizers</a> will test 100 populations of pipelines, each with 100 generations for a total of 10,000 pipelines. Using 10-fold cross validation, this represents 100,000 training runs. Even using Google Colab, this takes quite a while! To avoid running out of time on the Colab server (we get 12 hours of continuous run-time) we will set a maximum of 8 hours (480 minutes) for evaluation.  <a class="reference external" href="https://epistasislab.github.io/tpot/using/">TPOT is designed to be run for days</a> to thoroughly evaluate many pipelines, but the results can be quite good even from a few hours of training.</p>
<p>We set the following parameters in the call to the optimizer (feel free to change these and see how they affect the results):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scoring</span> <span class="pre">=</span> <span class="pre">neg_mean_absolute_error</span></code>: Our selected regression performance metric</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_time_mins</span> <span class="pre">=</span> <span class="pre">480</span></code>: Limit evaluation to 8 hours</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_jobs</span> <span class="pre">=</span> <span class="pre">-1</span></code>: Use all available cores on the machine</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbosity</span> <span class="pre">=</span> <span class="pre">2</span></code>: Show a limited amount of information while training</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cv</span> <span class="pre">=</span> <span class="pre">5</span></code>: Use 5-fold cross validation (default is 10)</p></li>
</ul>
<p>After we create the optimizer, we <code class="docutils literal notranslate"><span class="pre">fit</span></code> it to the training data as with any Scikit-Learn machine learning model. This starts the optimization process which will continue for 8 hours. During training, we can see a limited amount of information (change the <code class="docutils literal notranslate"><span class="pre">verbosity</span></code> to see more or less).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a tpot object with a few parameters</span>
<span class="n">tpot</span> <span class="o">=</span> <span class="n">TPOTRegressor</span><span class="p">(</span><span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">,</span> 
                    <span class="n">max_time_mins</span> <span class="o">=</span> <span class="mi">480</span><span class="p">,</span> 
                    <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">verbosity</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the tpot model on the training data</span>
<span class="n">tpot</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">training_targets</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Imputing missing values in feature set
</pre></div>
</div>
<div class="stderr docutils container">
<pre class="stderr literal-block">/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.
  warnings.warn(msg, category=DeprecationWarning)
</pre>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "c74dab0135534529a15c306e6cc5c2f8", "version_minor": 0, "version_major": 2}
</script><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
Generation 1 - Current best internal CV score: -8.850387930887832
</pre></div>
</div>
</div>
</div>
<p>Due to the time limit, we can see our model only was able to get through 15 generations. With 100 populations, this represents 1500 different individual pipelines that were evaluated, quit a few more than we would be able to try by hand!</p>
<p>Once the model has finished training, we can see the optimal pipeline by printing the <code class="docutils literal notranslate"><span class="pre">fitted_pipeline</span></code>. This represents the complete pipeline with the best performance metric (in this case the highest <code class="docutils literal notranslate"><span class="pre">neg_mean_absolute_error</span></code>) from cross validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show the final model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tpot</span><span class="o">.</span><span class="n">fitted_pipeline_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The TPOT optimization process is stochastic, meaning that <a class="reference external" href="https://epistasislab.github.io/tpot/using/">each run will produce different results</a>. If you run this notebook again, don’t worry if you see a different final pipeline!</p>
<p>To save the pipeline for future use, we can export it to a Python script.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Export the pipeline as a python script file</span>
<span class="n">tpot</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s1">&#39;tpot_exported_pipeline.py&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since we are in a Google Colab notebook, this will save it on the server where our notebook is running and the file  will only persist while we are connected. To download the pipeline onto a local machine from Google’s servers, we have to use the file helper functions (from <code class="docutils literal notranslate"><span class="pre">gooogle.colab</span></code>) to download it.</p>
<p>The file can be <a class="reference external" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/auto_ml/tpot_exported_pipeline.py">accessed on GitHub</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import file management</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">file</span>

<span class="c1"># Download the pipeline for local use</span>
<span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;tpot_exported_pipeline.py&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we want to look at all of the evaluated pipelines, we can see the <code class="docutils literal notranslate"><span class="pre">.evaluated_individuals_</span></code> attribute of the fitted optimizer. Be careful about running this as it will print out all 1500 pipelines that were tested!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># To examine all fitted models</span>
<span class="c1"># tpot.evaluated_individuals_</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, let’s test the entire fitted pipeline on the test dataset. After evaluating all the pipelines, TPOT saves the best one and trains it on all the training data, so we can evaluate the best one using the optimizer <code class="docutils literal notranslate"><span class="pre">.score</span></code> method. This will display the negative mean squared error, our regression metric.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate the final model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tpot</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">testing_features</span><span class="p">,</span> <span class="n">testing_targets</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>In the series of articles where we solved this problem by hand, we built a <code class="docutils literal notranslate"><span class="pre">GradientBoostedRegressor</span></code> model that achieved 9.1 mean absolute error on the test set. Automated machine learning has significantly improved on that score with a drastic reduction in the amount of development time. This “data science assistant” feels like the future of data science!</p>
<p>Here is the actual implementation of the final pipeline which I copy and pasted from the downloaded Python file. We can train and test it just to make sure that this score is correct!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports that the final pipeline needs</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoLarsCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span><span class="p">,</span> <span class="n">make_union</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Imputer</span>
<span class="kn">from</span> <span class="nn">tpot.builtins</span> <span class="kn">import</span> <span class="n">StackingEstimator</span>

<span class="c1"># Preprocessing steps</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>
<span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_features</span><span class="p">)</span>
<span class="n">training_features</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">training_features</span><span class="p">)</span>
<span class="n">testing_features</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testing_features</span><span class="p">)</span>

<span class="c1"># Final pipeline from TPOT</span>
<span class="n">exported_pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StackingEstimator</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">LassoLarsCV</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
    <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;lad&quot;</span><span class="p">,</span> 
                              <span class="n">max_depth</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> 
                              <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> 
                              <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">0.60</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit on the training data</span>
<span class="n">exported_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">training_targets</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After creating the optimized pipeline and training it, we can evaluate it on the testing set. As the models were not created with a <code class="docutils literal notranslate"><span class="pre">random_state</span></code>, we expect slightly different performance than the original results, but it should be fairly close.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make predictions on the testing data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">exported_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_features</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Absolute Error = </span><span class="si">%0.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">testing_targets</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>Sure enough, the mean absolute error is close to that from the optimizer <code class="docutils literal notranslate"><span class="pre">.score</span></code> method and considerably better than our manual pipeline building efforts.</p>
<p>From here, we can use the optimization results and try to further fine-tune the pipeline, or we can move on to important phases of the data science workflow. If we use this as the final model, we could spend time trying to intrepret the model (perhaps using <a class="reference external" href="https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime">LIME: Local Interpretable Model-Agnostic Explainations</a>) or reporting our results.</p>
</div>
</div>
<div class="section" id="conclusions">
<h1>Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">¶</a></h1>
<p>We saw how to use TPOT, an auto-ml Python library for automatically designing a machine learning pipeline. This tool will evaluate thousands of feature construction, feature selection, model selection, and hyperparameter tuning configurations in order to simplify the job of the data scientist. As machine learning is just one part of the data science workflow, auto-ml will not replace the data scientist, but allow her to spend time on more important aspects of the process. Automated machine learning is still in its early stages, but it appears to be a promising method for optimizing the often tedious and frustrating task of finding the best machine learning pipeline.</p>
<p>While being an early adopter does not always pay off, in this case, TPOT is mature enough to have a simple-to-use interface, but also new enough that you will be ahead of the curve if you are familiar with its use. With that in mind, find a problem and get out there are try to solve it! If you are looking for a place to start, <a class="reference external" href="https://www.kaggle.com/">Kaggle</a> (The Self-Proclaimed Home of Data Science) has many datasets and problems that are well-suited for application of auto-ml.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/22-automl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Jason Kuruzovich<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-32817743-6', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>